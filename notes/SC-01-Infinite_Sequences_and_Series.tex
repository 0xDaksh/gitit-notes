\documentclass[a4paper,8pt]{article}
\usepackage[a4paper, margin=15mm]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathfunc}

% Header
% ===========================

\title{Infinite Sequences and Series}
\author{Calculus Early Transcendentals by James Stewart (Chapter 11)}
\date{June 16\textsuperscript{th}, 2015}


% Document
% ===========================

\begin{document}
\maketitle
\pagenumbering{gobble}

\begin{outline}

  \dbullet{11.1.1 (Limits of Sequences)}
    A sequence \(\{a_n\}\) has the "limit" \(L\) and we write
    \[ \xlimit{n}{\infty}a_n = L \text{ or } a_n \rightarrow L\text{ as } n \rightarrow \infty \]
    if for every \(\epsilon > 0\), there is a corresponding integer \(N\) such that if \(n > N\)
    then \(|a_n - L| < \epsilon\).

  \tbullet{11.1.2}
    If \(\xlimit{x}{\infty} f(x) = L\) and \(f(n) = a_n\) when \(n\) is an integer, then \(\xlimit{n}{\infty} a_n = L\).

    \begin{proof}
      This merely follows from the definition of a limit in the continuous sense, but applied in a discrete sense.
    \end{proof}

  \tbullet{11.1.3 (Limit of Infinity)}
    The \(\xlimit{n}{\infty}a_n = \infty\) means that for every positive number \(M\) there is an integer \(N\) such that if \(n > N\)
    then \(a_n > M\).

  \tbullet{11.1.4 (Limit Laws)}
    If \(\{a_n\}\) and \(\{b_n\}\) are convergent sequences and \(c\) is a constant, then
    \begin{enumerate}
      \item \(\xlimit{n}{\infty} (a_n + b_n) = \xlimit{n}{\infty} a_n + \xlimit{n}{\infty} b_n\).
      \item \(\xlimit{n}{\infty} ca_n = c \xlimit{n}{\infty}a_n\).
      \item \(\xlimit{n}{\infty} (a_nb_n) = \xlimit{n}{\infty} a_n \cdot \xlimit{n}{\infty} b_n\).
      \item \(\xlimit{n}{\infty} (a_n/b_n) = \left(\xlimit{n}{\infty}a_n\right)/\left(\xlimit{n}{\infty}b_n\right)\) if \(\xlimit{n}{\infty}b_n \neq 0\).
      \item \(\xlimit{n}{\infty} a_n^p = \left[\xlimit{n}{\infty}a_n\right]^p\) if \(p > 0\) and \(a_n > 0\).
    \end{enumerate}

    \begin{proof}
      Proven in a similar manner to the limit laws of functions.
    \end{proof}

  \tbullet{11.1.5 (Squeeze Theorem)}
    If \(a_n \leq b_n \leq c_n\) for \(n \geq n_0\) and \(\xlimit{n}{\infty}a_n = \xlimit{n}{\infty} c_n = L\), then \(\xlimit{n}{\infty}b_n = L\).

    \begin{proof}
      Proof analogous to that of functions.
    \end{proof}

  \tbullet{11.1.6}
    If \(\xlimit{n}{\infty}|a_n| = 0\), then \(\xlimit{n}{\infty} a_n = 0\).

    \begin{proof}
      Let \(\epsilon > 0\). Then \(\exists N \in \bbn\) such that for all \(n \geq N\), \(||a_n|-0| < \epsilon\), meaning \(-\epsilon < |a_n| < \epsilon\).
      Observing the right inequality, we see \(|a_n| < \epsilon\) implies \(|a_n-0| < \epsilon\), completing the proof. Note the left inequality always
      holds true and can be disregarded.
    \end{proof}

  \tbullet{11.1.7}
    If \(\xlimit{n}{\infty} a_n = L\) and the function \(f\) is continuous at \(L\), then \[ \xlimit{n}{\infty} f(a_n) = f(L)\text{.} \]

    \begin{proof}
      Since \(f\) is continuous, we note the limit does exist, and the \(\delta-\epsilon\) definition holds; namely, \(\xlimit{x}{a} f(x) = f(L)\)
      means for every \(\epsilon > 0\), \(\exists \delta > 0\) such that \(0 < |x - a| < \delta\) implies \(|f(x)-f(L)| < \epsilon\). Now, let
      \(\epsilon > 0\) and take \(\delta > 0\) to be the value that satisfies the above definition. By hypothesis, there exists an \(N \in \bbn\) such
      that \(\forall n \geq N\), \(|a_n - L| < \delta\). But then \(|f(a_n) - f(L)| < \epsilon\) must also hold. Since \(\epsilon\) is arbitrary,
      \(\xlimit{n}{\infty} f(a_n) = f(L)\).
    \end{proof}

  \tbullet{11.1.8}
    The sequence \(\{r^n\}\) is convergent if \(-1 < r \leq 1\) and divergent for all other values of \(r\):
    \[
      \xlimit{n}{\infty} r^n = \begin{cases}
          0 &\text{ if } -1 < r < 1 \\
          1 &\text{ if } r = 1
        \end{cases}
    \]

  \dbullet{11.1.9 (Monotonicity)}
    A sequence \(\{a_n\}\) is called "increasing" if \(a_n < a_{n+1}\) for all \(n \geq 1\), that is \(a_1 < a_2 < \cdots\). It is called "decreasing"
    if \(a_n > a_{n+1}\) for all \(n \geq 1\). It is called "monotonic" if it is either increasing or decreasing.

  \dbullet{11.1.10 (Boundedness)}
    A sequence \(\{a_n\}\) is "bounded above" if there is a number \(M\) such that \(a_n \leq M\) for all \(n \geq 1\). It is "bounded below" if
    there is a number \(m\) such that \(m \leq a_n\) for all \(n \geq 1\). If it is bounded above and below, then \(\{a_n\}\) is a "bounded sequence."

  \tbullet{11.1.11 (Completeness Axiom)}
    For the set \(\bbr\) of real numbers, if \(S\) is a nonempty set of real numbers that has an upper bound \(M\), then \(S\) has a "least upper bound"
    or "supremum." Likewise, \(S\) also has a "least lower bound" or "infimum."

  \tbullet{11.1.12 (Monotonic Sequence Theorem)}
    Every bounded, monotonic sequence is convergent.

    \begin{proof}
      Suppose \(\{a_n\}\) is an increasing sequence. Since \(\{a_n\}\) is bounded, the set \(S = \{a_n : n \geq 1\}\) has an upper bound. By the Completeness
      Axiom, it has a supremum L. Given \(\epsilon > 0\), \(L - \epsilon\) is not an upper bound for \(S\). Therefore \(a_N > L - \epsilon\) for some
      integer \(N\). But since the sequence is increasing, \(a_n \geq a_N\) for every \(n > N\). Thus if \(n > N\) we have \(a_n > L-\epsilon\) which
      implies \(0 \leq L - a_n < \epsilon\) since \(a_n \leq L\). Therefore \(|L-a_n| < \epsilon\) whenever \(n > N\) and \(\xlimit{n}{\infty} a_n = L\).
      A similar proof holds when \(\{a_n\}\) is decreasing.
    \end{proof}

  \tbullet{11.2.1 (Convergence/Divergence of Series)}
    Given a series \(\sum_{n=1}^{\infty} a_n = a_1 + a_2 + \cdots\), let \(s_n\) denote its \(\spscript{n}{th}\) partial sum:
    \[ s_n = \sum_{i=1}^n a_i = \inflatedot[+]{a}{n}\text{.} \] If the sequence \(\{s_n\}\) is convergent and \(\xlimit{n}{\infty} s_n = s\)
    exists as a real number, then the series \(\sum a_n\) is called "convergent" and we write
    \[\inflatedot[+]{a}{n} + \cdots = s\text{ or } \sum_{n=1}^{\infty} a_n = s\text{.} \]
    The number \(s\) is called the "sum" of the series. Otherwise, the series is "divergent."

  \tbullet{11.2.2 (Geometric Series)}
    The geometric series \[ \sum_{n=1}^{\infty} ar^{n-1} = a + ar + ar^2 + \cdots \] is convergent if \(|r| < 1\) and its sum is
    \[ \sum_{n=1}^{\infty} ar^{n-1} = \frac{a}{1-r},\quad |r| < 1\text{.} \] If \(|r| \geq 1\), the geometric series is divergent.

    \begin{proof}
      We consider just the \(|r| < 1\) case, since \(r = 1\) and \(r > 1\) are obvious. Note that
      \begin{align*}
        s_n &= a + ar + ar^2 + \cdots + ar^{n-1} \\
        rs_n &= ar + ar^2 + \cdots + ar^{n-1} + ar^n\text{.}
      \end{align*}
      Subtracting the two equations, we get
      \begin{align*}
        s_n - rs_n &= a - ar^n \\
        s_n &= \frac{a(1-r^n)}{1-r}
      \end{align*}
      By Theorem 11.1.8, \(r^n \rightarrow \infty\) as \(n \rightarrow \infty\), and thus \(s_n = a/(1-r)\).
    \end{proof}

  \tbullet{11.2.3}
    If the series \(\sum_{n=1}^{\infty}\) is convergent, then \(\xlimit{n}{\infty} = 0\).

    \begin{proof}
      Let \(s_n = \inflatedot[+]{a}{n}\). Then \(a_n = s_n - s_{n-1}\). Since \(\sum a_n\) is convergent, the sequence \(\{s_n\}\) is convergent.
      Let \(\xlimit{n}{\infty} s_n = s\). Since \(n - 1 \rightarrow \infty\) as \(n \rightarrow \infty\), we also have \(\xlimit{n}{\infty} s_{n-1} = s\).
      Therefore
      \begin{align*}
        \xlimit{n}{\infty} a_n &= \xlimit{n}{\infty}(s_n - s_{n-1}) = \xlimit{n}{\infty} s_n - \xlimit{n}{\infty} s_{n-1} \\
                               &= s - s = 0\text{.}
      \end{align*}
    \end{proof}

  \tbullet{11.2.4 (Divergence Test)}
    If \(\xlimit{n}{\infty} a_n\) does not exist or if \(\xlimit{n}{\infty} a_n \neq 0\), then the series \(\sum_{n=1}^{\infty} a_n\) is divergent.

    \begin{proof}
      Contrapositive of Theorem 11.2.3.
    \end{proof}

\end{outline}

\end{document}
